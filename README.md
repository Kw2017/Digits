# Digits

When testing using 5 training epochs, increasing the dropout rate resulted in decreases in both training and test set accuracy.

![](https://raw.githubusercontent.com/Kw2017/Digits/main/chart.png)

Furthermore, increasing the number of Epochs did not compensate for the accuracy loss caused by the dropout rate increase.

| Dropout Rate | Epochs | Train 1 | Train 2 | Train 3 | Train Avg | Test 1 | Test 2 | Test 3 | Test Avg |
|--------------|--------|---------|---------|---------|-----------|--------|--------|--------|----------|
|0.4           |10      |0.9724   |0.9726   |0.9736   |0.9728     |0.9778  |0.9783  |0.9786  |0.9782    |
|0.4           |15      |0.9775   |0.9781   |0.9778   |0.9778     |0.9789  |0.9789  |0.9775  |0.9785    |
|0.4           |20      |0.9802   |0.9795   |0.9804   |0.9800     |0.9791  |0.9791  |0.9802  |0.9800    |
|0.4           |25      |0.9818   |0.9819   |0.9814   |0.9817     |0.9794  |0.9794  |0.9808  |0.9801    |
|0.5           |10      |0.9649   |0.9636   |0.9619   |0.9634     |0.9755  |0.9755  |0.9766  |0.9759    |
|0.5           |15      |0.9689   |0.9685   |0.9690   |0.9688     |0.9792  |0.9792  |0.9781  |0.9789    |
|0.5           |20      |0.9711   |0.9708   |0.9707   |0.9708     |0.9784  |0.9784  |0.9803  |0.9790    |
|0.5           |25      |0.9731   |0.9735   |0.9723   |0.9729     |0.9789  |0.9789  |0.9778  |0.9784    |
|0.6           |10      |0.9507   |0.9505   |0.9523   |0.9511     |0.9744  |0.9744  |0.9726  |0.9730    |
|0.6           |15      |0.9538   |0.9553   |0.9551   |0.9547     |0.9737  |0.9737  |0.9752  |0.9749    |
|0.6           |20      |0.9579   |0.9595   |0.9576   |0.9583     |0.9744  |0.9744  |0.9770  |0.9756    |
|0.6           |25      |0.9608   |0.9588   |0.9616   |0.9604     |0.9762  |0.9762  |0.9768  |0.9767    |
